# Perplexity Analysis

Analyse de perplexit√© pour d√©tecter les patterns de texte g√©n√©r√©s par IA.

## Principe

La **perplexit√©** mesure √† quel point un mod√®le de langage est "surpris" par un texte.

- **Perplexit√© basse** ‚Üí texte pr√©visible, patterns communs ‚Üí potentiellement IA
- **Perplexit√© haute** ‚Üí texte vari√©, tournures originales ‚Üí potentiellement humain

Le script utilise Mistral-7B pour calculer la perplexit√© de chaque phrase, puis classe les r√©sultats :

| Score | Marqueur | Interpr√©tation |
|-------|----------|----------------|
| < 10  | ü§ñü§ñ | Tr√®s suspect (patterns IA typiques) |
| < 20  | ü§ñ | Suspect |
| < 40  | ‚ùì | Incertain |
| ‚â• 40  | üë§ | Probablement humain |

**Seuil d'alerte** : perplexit√© < 15

### Burstiness

La **burstiness** mesure la variation des longueurs de phrases (en tokens).

- **IA** ‚Üí phrases uniformes ‚Üí burstiness basse
- **Humain** ‚Üí phrases vari√©es ‚Üí burstiness haute

Deux m√©triques compl√©mentaires :

| M√©trique | Calcul | Usage |
|----------|--------|-------|
| **Burstiness** | √©cart-type des longueurs | Variation absolue |
| **Fano factor** | variance / moyenne | Variation normalis√©e (comparable entre textes) |

## Pr√©requis

### Mat√©riel
- **GPU NVIDIA** avec support CUDA
- **~16 GB VRAM** recommand√©s (Mistral-7B en float16)

### Logiciel
- Python 3.11+
- CUDA toolkit install√©
- Driver NVIDIA r√©cent

Pour les GPU Blackwell (RTX 50xx), PyTorch nightly avec CUDA 12.8 est requis (configur√© dans `pyproject.toml`).

## Installation

```bash
cd scripts/perplexity
uv sync  # Installe les d√©pendances
```

## Usage

### Analyse d'un fichier (d√©taill√©e)
```bash
uv run test_perplexity.py chapitre.md
```

Affiche :
- Stats du fichier (mots, phrases, filtr√©es)
- Stats de perplexit√© (moyenne, m√©diane, √©cart-type)
- Stats de burstiness (std, Fano factor)
- Classement de toutes les phrases par perplexit√©

### Analyse batch (tous les chapitres)
```bash
uv run test_perplexity.py
```

Tableau r√©capitulatif de tous les fichiers `chapitre-*.md` dans `story/chapters/`.

### Test d'une phrase unique
```bash
uv run test_perplexity.py -p "Il est fondamental de comprendre que..."
```

### Entr√©e par pipe
```bash
cat mon_texte.txt | uv run test_perplexity.py
echo "Ma phrase" | uv run test_perplexity.py
```

### Aide
```bash
uv run test_perplexity.py -h
```

## Notes techniques

### D√©coupage des phrases
- Split sur `.!?` suivi d'une majuscule
- Gestion des guillemets fran√ßais `¬´¬ª`
- Fusion des phrases courtes (< 6 mots) avec les adjacentes

### Filtrage
- √âl√©ments markdown ignor√©s (titres, s√©parateurs, liens)
- Les phrases tr√®s courtes sont fusionn√©es, pas supprim√©es

### Concurrence
Un fichier lock (`.perplexity.lock`) emp√™che les ex√©cutions simultan√©es pour √©viter les conflits GPU.

## Limitations

- La perplexit√© seule n'est pas un d√©tecteur IA fiable
- Les dialogues courts, expressions courantes et textes simples ont naturellement une perplexit√© basse
- R√©sultats √† interpr√©ter comme indicateurs, pas comme verdict

## TODO

- [ ] Two-phase processing: use an instruct model for semantic sentence splitting first, then run perplexity analysis. This should improve accuracy by ensuring sentences are split at natural boundaries rather than relying on punctuation heuristics.
